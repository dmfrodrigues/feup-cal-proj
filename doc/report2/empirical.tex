\chapter{Empirical complexity analysis} \label{empirical}

All performance tests were run on the same machine, with the following specifications:  \vspace{1em} \\
\begin{tabular}{l l}
    Operating system & Ubuntu 18.04 \\
    CPU              & Intel® Core™ i7-4750HQ @ 2.00GHz (4 cores, 8 threads) \\
    Memory           & 8GB 1600MHz DDR3 SDRAM
\end{tabular}

\section{Shortest path}

As expected from complexity analysis, which yielded $O((|E|+|V|) \log |V|)$, \hyperref[alg-dijkstra]{Dijkstra's algorithm} running time is approximately $\log$-linear in the number of nodes.\par
As for the \hyperref[alg-astar]{A* algorithm} we used the map data to empirically evaluate its complexity. But first, two initial observations must be made to better understand its complexity as a function of path weight $W$. An A* algorithm using a purely greedy heuristic has time complexity linear in $W$, since it only explores nodes that will then be added to the path. Dijkstra's algorithm has time complexity quadratic in $W$, since it explores all nodes in a \emph{weight radius} of at most $W$, covering a number of nodes proportional to $W^2$.\par
We can now state this admissible A* algorithm's time complexity as a function of $W$ lies somewhere between $O(W)$ and $O(W^2)$, since it always explores at most as many nodes as Dijkstra's algorithm, but it must explore more nodes than a purely greedy algorithm so it can have more insight into possible optimal shortest paths.

\write18{ if [ ! -f gr6N6Ap.png ] ; then curl https://i.imgur.com/gr6N6Ap.png -o gr6N6Ap.png ; fi ; }
\write18{ if [ ! -f b6wY2NU.png ] ; then curl https://i.imgur.com/b6wY2NU.png -o b6wY2NU.png ; fi ; }
\begin{figure}[H]
    \centering
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[trim={20px 0 10px 0}, clip, scale=0.4]{gr6N6Ap}
        % \caption{\hyperref[algorithm-shortestpath-dijkstra]{Dijkstra's algorithm}}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[trim={20px 0 10px 0}, clip, scale=0.4]{b6wY2NU}
        % \caption{\hyperref[algorithm-shortestpath-astar]{A* algorithm}}
    \end{subfigure}
    \caption{Shortest path algorithms empirical complexity}
\end{figure}

\section{Variant of Kosaraju's algorithm}
This \hyperref[algorithm-scc-kosaraju-v]{variant of Kosaraju's algorithm} has an approximately linear time complexity in the number of nodes, as otherwise expected from the theoretical complexity analysis $O(|V|+|E|)$.

\write18{ if [ ! -f vcDppRN.png ] ; then curl https://i.imgur.com/vcDppRN.png -o vcDppRN.png ; fi ; }
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{vcDppRN}
    \caption{\hyperref[algorithm-scc-kosaraju-v]{Variant of Kosaraju's algorithm} empirical complexity}
\end{figure}

\section{Vertical stripes}

As expected from theoretical complexity analysis, which yields $O(\Delta x / \Delta + |S| \log |S|)$, the \hyperref[algorithm-vstripes]{vertical stripes algorithm/data structure} initialization time is $\log$-linear with the size $|S|$ of the points set (a).\par
As for (b), these results show that the impact of the $\Delta$ factor is negligible in the time complexity of the vertical stripes algorithm on sets of points of considerable size (i.e. 1000000).

\write18{ if [ ! -f ahcy7lO.png ] ; then curl https://i.imgur.com/ahcy7lO.png -o ahcy7lO.png ; fi ; }
\write18{ if [ ! -f G0umKaD.png ] ; then curl https://i.imgur.com/G0umKaD.png -o G0umKaD.png ; fi ; }
\begin{figure}[H]
    \centering
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[trim={20px 0 10px 0}, clip, scale=0.4]{ahcy7lO}
        \caption{Varying number of points ($\Delta$ = 0.025)}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[trim={20px 0 10px 0}, clip, scale=0.4]{G0umKaD}
        \caption{Varying $\Delta$ (number of points = 1000000)}
    \end{subfigure}
    \caption{\hyperref[algorithm-vstripes]{Vertical stripes algorithm} empirical complexity}
\end{figure}
\pagebreak
Empirical analysis also allowed us to verify queries to the data structure are very fast (in the order of magnitude of $\SI{1}{\mu s}$), and that its time complexity is $O(\log |S|)$.

\write18{ if [ ! -f CInL9tQ.png ] ; then curl https://i.imgur.com/CInL9tQ.png -o CInL9tQ.png ; fi ; }
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{CInL9tQ}
    \caption{\hyperref[algorithm-vstripes]{Vertical stripes queries} empirical complexity}
\end{figure}

\section{Held-Karp algorithm}

We can deduce from this graph that \hyperref[algorithm-tsp-heldkarp]{Held-Karp algorithm}'s time complexity is superpolynomial (or at least polynomial with a large exponent), which is consistent with the theoretical complexity analysis $O(N^2 2^N)$.

\write18{ if [ ! -f yQHAGxj.png ] ; then curl https://i.imgur.com/yQHAGxj.png -o yQHAGxj.png ; fi ; }
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{yQHAGxj}
    \caption{\hyperref[algorithm-tsp-heldkarp]{Held-Karp algorithm} empirical complexity}
\end{figure}
\pagebreak

\section{Iterations}
As expected from theoretical complexity analysis, when keeping all other parameters constant both iterations' time complexity is linear in the number of clients $C$.

\write18{ if [ ! -f tcMr14Z.png ] ; then curl https://i.imgur.com/tcMr14Z.png -o tcMr14Z.png ; fi ; }
\write18{ if [ ! -f aabSfZF.png ] ; then curl https://i.imgur.com/aabSfZF.png -o aabSfZF.png ; fi ; }
\begin{figure}[H]
    \centering
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[trim={20px 0 10px 0}, clip, scale=0.4]{tcMr14Z}
        % \caption{\hyperref[iterations-1]{1st iteration}}
    \end{subfigure}
    \begin{subfigure}{0.49\textwidth}
        \centering
        \includegraphics[trim={20px 0 10px 0}, clip, scale=0.4]{aabSfZF}
        % \caption{\hyperref[iterations-2]{2nd iteration}}
    \end{subfigure}
    \caption{\hyperref[iterations]{Implemented iterations}' empirical complexity}
\end{figure}
